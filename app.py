"""
Autoanosis AI Backend v3
Professional Flask backend for AI Assistant with Medical Context
Deployed on Render.com
"""

import os
import logging
import time
import uuid
from collections import defaultdict
from datetime import datetime
from flask import Flask, request, jsonify
from flask_cors import CORS
from openai import OpenAI
from identity import verify_identity_token

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Initialize Flask app
app = Flask(__name__)

# Configure CORS - allow requests from autoanosis.com
CORS(app, resources={
    r"/*": {
        "origins": [
            "https://autoanosis.com",
            "https://www.autoanosis.com"
        ],
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type", "X-User-ID"],
        "supports_credentials": True
    }
})

# Configure OpenAI client (lazy initialization)
openai_client = None

def get_openai_client():
    global openai_client
    if openai_client is None:
        openai_client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
    return openai_client

# Token Bridge Configuration
TOKEN_SECRET = os.environ.get("AUTOANOSIS_IDENTITY_SECRET", "CHANGE_THIS_SECRET")

# Rate limiting storage (in-memory)
rate_limit_storage = defaultdict(list)
RATE_LIMIT_USER = 20  # 20 requests per 10 minutes for authenticated users
RATE_LIMIT_WINDOW = 600  # 10 minutes in seconds

# Session Memory Storage (in-memory)
# Format: {conversation_id: {"messages": [...], "last_activity": timestamp, "user_id": int}}
conversation_storage = {}
MAX_CONVERSATION_HISTORY = 10  # Keep last 10 messages per conversation
CONVERSATION_TTL = 3600  # 1 hour

# System prompt for Autoanosis health assistant
SYSTEM_PROMPT_BASE = """Î•Î¯ÏƒÎ±Î¹ Î¿ Autoanosis Assistant, Î­Î½Î±Ï‚ ÎµÎ¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î¿Ï‚ Î²Î¿Î·Î¸ÏŒÏ‚ Ï…Î³ÎµÎ¯Î±Ï‚ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬.

Î Î±ÏÎ­Ï‡ÎµÎ¹Ï‚:
- Î‘ÎºÏÎ¹Î²ÎµÎ¯Ï‚ ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„Î·Î¼Î¿Î½Î¹ÎºÎ¬ Ï„ÎµÎºÎ¼Î·ÏÎ¹Ï‰Î¼Î­Î½ÎµÏ‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Ï…Î³ÎµÎ¯Î±Ï‚
- Î¦Î¹Î»Î¹ÎºÎ­Ï‚ ÎºÎ±Î¹ ÎºÎ±Ï„Î±Î½Î¿Î·Ï„Î­Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚
- Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· ÏƒÎµ Î¸Î­Î¼Î±Ï„Î± Ï…Î³ÎµÎ¯Î±Ï‚, Ï†Î±ÏÎ¼Î¬ÎºÏ‰Î½, ÏƒÏ…Î¼Ï€Ï„Ï‰Î¼Î¬Ï„Ï‰Î½

Î£Î·Î¼Î±Î½Ï„Î¹ÎºÏŒ:
- Î”Î•Î Î±Î½Ï„Î¹ÎºÎ±Î¸Î¹ÏƒÏ„Î¬Ï‚ Î¹Î±Ï„ÏÎ¹ÎºÎ® ÏƒÏ…Î¼Î²Î¿Ï…Î»Î®
- Î£Ï…Î½Î¹ÏƒÏ„Î¬Ï‚ Ï€Î¬Î½Ï„Î± ÎµÏ€Î¯ÏƒÎºÎµÏˆÎ· ÏƒÎµ Î³Î¹Î±Ï„ÏÏŒ Î³Î¹Î± ÏƒÎ¿Î²Î±ÏÎ¬ Î¸Î­Î¼Î±Ï„Î±
- Î‘Ï€Î±Î½Ï„Î¬Ï‚ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬"""

def check_rate_limit(identifier: str) -> bool:
    """Check if identifier has exceeded rate limit"""
    current_time = time.time()
    
    # Clean old entries
    rate_limit_storage[identifier] = [
        t for t in rate_limit_storage[identifier] 
        if current_time - t < RATE_LIMIT_WINDOW
    ]
    
    # Check limit
    if len(rate_limit_storage[identifier]) >= RATE_LIMIT_USER:
        return False
    
    # Record this request
    rate_limit_storage[identifier].append(current_time)
    return True

def cleanup_old_conversations():
    """Remove expired conversations"""
    current_time = time.time()
    expired = [
        conv_id for conv_id, data in conversation_storage.items()
        if current_time - data.get('last_activity', 0) > CONVERSATION_TTL
    ]
    for conv_id in expired:
        del conversation_storage[conv_id]
        logger.info(f"Cleaned up expired conversation: {conv_id}")

def get_conversation_history(conversation_id: str) -> list:
    """Get conversation history for context"""
    if conversation_id not in conversation_storage:
        return []
    return conversation_storage[conversation_id].get('messages', [])

def save_conversation_message(conversation_id: str, user_id: int, role: str, content: str):
    """Save message to conversation history"""
    if conversation_id not in conversation_storage:
        conversation_storage[conversation_id] = {
            'messages': [],
            'user_id': user_id,
            'last_activity': time.time()
        }
    
    conv = conversation_storage[conversation_id]
    conv['messages'].append({'role': role, 'content': content})
    conv['last_activity'] = time.time()
    
    # Keep only last N messages
    if len(conv['messages']) > MAX_CONVERSATION_HISTORY:
        conv['messages'] = conv['messages'][-MAX_CONVERSATION_HISTORY:]

def build_medical_context(medical_snapshot: dict) -> str:
    """Build medical context string from snapshot"""
    if not medical_snapshot or not isinstance(medical_snapshot, dict):
        return ""
    
    context_parts = []
    
    # Medications
    meds = medical_snapshot.get('autoanosis_medications')
    if meds and isinstance(meds, list) and len(meds) > 0:
        med_names = [m.get('name', '') for m in meds if isinstance(m, dict) and m.get('name')]
        if med_names:
            context_parts.append(f"Î¦Î¬ÏÎ¼Î±ÎºÎ± Ï€Î¿Ï… Ï€Î±Î¯ÏÎ½ÎµÎ¹: {', '.join(med_names)}")
    
    # Conditions
    conditions = medical_snapshot.get('autoanosis_conditions')
    if conditions and isinstance(conditions, list) and len(conditions) > 0:
        cond_names = [c.get('name', '') for c in conditions if isinstance(c, dict) and c.get('name')]
        if cond_names:
            context_parts.append(f"Î Î±Î¸Î®ÏƒÎµÎ¹Ï‚: {', '.join(cond_names)}")
    
    # Allergies
    allergies = medical_snapshot.get('autoanosis_allergies')
    if allergies and isinstance(allergies, list) and len(allergies) > 0:
        allergy_names = [a.get('name', '') for a in allergies if isinstance(a, dict) and a.get('name')]
        if allergy_names:
            context_parts.append(f"Î‘Î»Î»ÎµÏÎ³Î¯ÎµÏ‚: {', '.join(allergy_names)}")
    
    # Medical Memory (recent notes)
    memory = medical_snapshot.get('autoanosis_medical_memory')
    if memory and isinstance(memory, list) and len(memory) > 0:
        recent = memory[:3]  # Last 3 entries
        notes = [m.get('note', '') for m in recent if isinstance(m, dict) and m.get('note')]
        if notes:
            context_parts.append(f"Î ÏÏŒÏƒÏ†Î±Ï„ÎµÏ‚ ÏƒÎ·Î¼ÎµÎ¹ÏŽÏƒÎµÎ¹Ï‚: {'; '.join(notes)}")
    
    if not context_parts:
        return ""
    
    return "\n\nðŸ“‹ Î Î¡ÎŸÎ£Î©Î Î™ÎšÎ‘ Î™Î‘Î¤Î¡Î™ÎšÎ‘ Î”Î•Î”ÎŸÎœÎ•ÎÎ‘ Î§Î¡Î—Î£Î¤Î—:\n" + "\n".join(context_parts) + "\n\nÎ§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Î±Ï…Ï„Î¬ Ï„Î± ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± Î³Î¹Î± Î½Î± Î´ÏŽÏƒÎµÎ¹Ï‚ Ï€ÏÎ¿ÏƒÏ‰Ï€Î¿Ï€Î¿Î¹Î·Î¼Î­Î½ÎµÏ‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚."

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        "status": "healthy",
        "service": "autoanosis-ai-backend",
        "version": "3.0.0",
        "features": ["medical_snapshot", "session_memory", "rate_limiting"]
    }), 200

@app.route('/chat', methods=['POST'])
def chat():
    # Cleanup old conversations periodically
    if len(conversation_storage) > 100:
        cleanup_old_conversations()
    
    data = request.json
    user_message = data.get("message")
    if not user_message:
        return jsonify({"error": "No message provided"}), 400

    # Get user_id from identity_token (Token Bridge)
    user_id = None
    identity_token = data.get("identity_token")
    
    if identity_token:
        is_valid, payload, error = verify_identity_token(identity_token)
        if is_valid and payload:
            user_id = payload.get("uid")
            logger.info(f"User authenticated via identity token: {user_id}")
        else:
            logger.warning(f"Identity token verification failed: {error}")
            return jsonify({"error": "Invalid identity token"}), 401
    else:
        logger.warning("No identity token provided")
        return jsonify({"error": "Identity token required"}), 401
    
    # Rate limiting (per user)
    rate_limit_key = f"user_{user_id}"
    if not check_rate_limit(rate_limit_key):
        return jsonify({"error": "Rate limit exceeded. Please try again later."}), 429

    # Get conversation ID
    conversation_id = data.get("conversation_id")
    if not conversation_id:
        conversation_id = f"conv_{int(time.time())}_{uuid.uuid4().hex[:8]}"
        logger.info(f"Generated new conversation ID: {conversation_id}")

    # Build system prompt
    system_prompt = SYSTEM_PROMPT_BASE
    
    # Add medical context if available
    medical_snapshot = data.get("medical_snapshot")
    if medical_snapshot:
        medical_context = build_medical_context(medical_snapshot)
        if medical_context:
            system_prompt += medical_context
            logger.info(f"Medical context injected for user {user_id}")
        else:
            logger.info(f"Medical snapshot provided but empty for user {user_id}")
    else:
        logger.info(f"No medical snapshot provided for user {user_id}")

    # Get conversation history
    history = get_conversation_history(conversation_id)
    
    # Build messages for OpenAI
    messages = [{"role": "system", "content": system_prompt}]
    
    # Add conversation history (last N messages)
    if history:
        messages.extend(history)
        logger.info(f"Added {len(history)} messages from conversation history")
    
    # Add current user message
    messages.append({"role": "user", "content": user_message})

    try:
        client = get_openai_client()
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.7
        )
        ai_response = response.choices[0].message.content
        
        # Save to conversation history
        save_conversation_message(conversation_id, user_id, "user", user_message)
        save_conversation_message(conversation_id, user_id, "assistant", ai_response)
        
        logger.info(f"Chat interaction: User={user_id}, Conversation={conversation_id}")
        
        return jsonify({
            "reply": ai_response,
            "conversation_id": conversation_id
        })
    except Exception as e:
        logger.error(f"OpenAI Error: {e}")
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=10000)
